<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_l45_qwf_xw">
    <title>Meet <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/DPM-LongOnly"
        /></title>
    <shortdesc><ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/DPM-LongOnly"
            /><sup>TM</sup> (SCH) is a central point of control for all of your dataflow pipelines.
            <ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/DPM-short"/>
        allows teams to build and execute large numbers of complex dataflows at scale. </shortdesc>
    <conbody>
        <p><indexterm>StreamSets Control Hub<indexterm>overview</indexterm></indexterm>Teams of data
            engineers use the shared repository provided with <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/DPM-short"/> to
            collaboratively build pipelines. <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/DPM-short"/>
            provides full life cycle management of the pipelines, allowing you to track the version
            history and giving you full control of the evolving development process. <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/DPM-short"/>
            lets you deploy and execute dataflows at scale on manually administered or automatically
            provisioned <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>s
            or on edge devices using <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/Edge-Long"/>.
            You can map multiple dataflows in a single visual topology and can view real-time
            statistics to measure dataflow performance across each topology, from end-to-end or
            point-to-point. You can also monitor alerts to ensure that incoming data meets business
            requirements for availability and accuracy. </p>
        <p>Multiple types of users within your organization can perform different roles in <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/DPM-short"/>.
            For example, a data architect typically creates a high-level design of how data needs to
            flow through multiple systems. Teams of data engineers use this high-level design to
            build individual pipelines in <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/DPM-short"/>
            <ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/PDesigner"/> or
            a development <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>.
            The data engineers then publish the finished pipelines to <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/DPM-short"/>. </p>
        <p>A DevOps or site reliability engineer adds published pipelines to jobs and then starts
            the jobs across multiple execution <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>s
            or <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/Edge-Long-Plural"
            />, running a remote pipeline instance on each execution component. Data architects map
            the related jobs into a single visual topology, and then use the topology to monitor and
            measure the complete dataflow. DevOps engineers create data SLAs (service level
            agreements) for topologies to define thresholds that the dataflows cannot exceed,
            ensuring that data is delivered in a timely manner.</p>
        <p>Letâ€™s take a closer look at what data architects, data engineers, and DevOps engineers
            can accomplish with <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/DPM-short"
            />.</p>
    </conbody>
</concept>
